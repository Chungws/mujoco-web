# Feature: VLA Execution Server

**Status:** Week 3-4 - Phase 2 Mock + Octo-Small Services Complete
**Priority:** HIGH
**Timeline:** Week 3-5 (3 weeks)
**Target Date:** Week 5 completion
**Related ADR:** [ADR-003: VLA Server Separation](../ARCHITECTURE/ADR_003-VLA_Server_Separation.md)
**Phase 1 Progress:** 26/26 tests passing (config + MuJoCo env)
**Phase 2 Progress:** Mock + Octo-Small services complete (13 + 12 tests passing) âœ… PR #35, PR #36
**Architecture:** Microservice (vla-server-base + independent model services)

---

## ðŸ“‹ Overview

**New Architecture (Phase 2 Restructure):**
- **vla-server-base**: Lightweight common library (BaseAdapter, MuJoCo wrapper, schemas)
- **vla-servers/**: Independent model services (mock, octo-small, smolvla)
- **Dependency Isolation**: Each model service has its own Python version and ML dependencies
- **Microservice Pattern**: Each model runs as a separate FastAPI service with independent lifecycle

This design solves dependency conflicts (e.g., octo requires Python 3.11 + TensorFlow 2.15, while smolvla needs Python 3.12 + PyTorch 2.9+) by complete isolation.

**Key Features:**
- Stateless MuJoCo simulation (XML-based, no file system dependency)
- VLA Adapter pattern (model-specific preprocessing/postprocessing)
- Dynamic robot/scene composition
- Episode generation (RT-1/Octo standard: 5 Hz, 15s max)
- State-based recording (qpos, qvel, time)
- GPU/CPU/MPS support

---

## ðŸŽ¯ Objectives

### MVP Scope

**What's Included:**
- âœ… 1 robot (Franka Emika Panda)
- âœ… 1 scene (Table pick-and-place)
- âœ… 2 VLA models (Octo-Small 27M, SmolVLA 450M)
- âœ… Adapter pattern (model-specific input/output handling)
- âœ… Stateless MuJoCo (XML string composition)
- âœ… Episode execution (max 15 seconds @ 5 Hz = 75 steps)
- âœ… Action/state recording
- âœ… HTTP API (POST /execute)
- âœ… MacBook compatible (CPU/MPS mode)

**What's Deferred (Post-MVP):**
- âŒ Multiple robots (WidowX, UR5)
- âŒ Multiple scenes (Kitchen, Warehouse)
- âŒ Model fine-tuning endpoints
- âŒ Real-time streaming
- âŒ Episode caching

---

## ðŸ—ï¸ Architecture

### New Microservice Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (Gateway)                                          â”‚
â”‚  - Routes requests to model services                        â”‚
â”‚  - POST /api/vla/execute?model_id=octo-small               â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â†’ vla-servers/mock/ (Port 8001, Python 3.9+)
     â”‚   â””â”€ Uses: vla-server-base (path dependency)
     â”‚
     â”œâ”€â†’ vla-servers/octo-small/ (Port 8002, Python 3.11)
     â”‚   â”œâ”€ Uses: vla-server-base (path dependency)
     â”‚   â””â”€ ML: tensorflow==2.15.0, jax, flax, octo
     â”‚
     â””â”€â†’ vla-servers/smolvla/ (Port 8003, Python 3.12)
         â”œâ”€ Uses: vla-server-base (path dependency)
         â””â”€ ML: torch>=2.9.0, transformers
```

### High-Level Flow

```
Backend â†’ HTTP POST /execute (to specific model service)
  â†“
Model Service (e.g., octo-small):
  1. Parse request (robot_id, scene_id, instruction)
  2. Compose MuJoCo XML (robot + scene) [from vla-server-base]
  3. Create MuJoCo environment (from XML string) [from vla-server-base]
  4. Use model-specific adapter (OctoSmallAdapter)
  5. Run episode loop (max 15s @ 5 Hz):
     a. Get observation (camera + proprioception)
     b. Adapter preprocessing (model-specific format)
     c. VLA inference (action from observation + instruction)
     d. Adapter postprocessing (standardize to 8-dim action)
     e. MuJoCo step (apply action, update state)
     f. Record (action, qpos, qvel, time)
     g. Check termination (time limit)
  6. Return episode data
  â†“
Response: {actions, states, duration_ms, metadata}
```

### Component Diagram

#### vla-server-base (Common Library - Workspace Member)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  vla-server-base/  (Python 3.9+, NO ML libs)          â”‚
â”‚                                                         â”‚
â”‚  â”œâ”€ base_adapter.py      # VLAModelAdapter ABC        â”‚
â”‚  â”œâ”€ mujoco_env.py        # MuJoCo wrapper             â”‚
â”‚  â”œâ”€ schemas.py           # Common types               â”‚
â”‚  â””â”€ server_utils.py      # FastAPI helpers            â”‚
â”‚                                                         â”‚
â”‚  Dependencies: fastapi, pydantic, mujoco, numpy       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Each Model Service (Independent - NOT Workspace Member)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  vla-servers/octo-small/  (Python 3.11)                â”‚
â”‚                                                         â”‚
â”‚  â”œâ”€ src/octo_service/                                  â”‚
â”‚  â”‚   â”œâ”€ adapter.py       # OctoSmallAdapter           â”‚
â”‚  â”‚   â””â”€ server.py        # FastAPI app                â”‚
â”‚  â”‚                                                      â”‚
â”‚  â”œâ”€ pyproject.toml                                     â”‚
â”‚  â”‚   # vla-server-base = { path = "../../vla-server-base" }
â”‚  â”‚   # tensorflow==2.15.0, jax, flax, octo            â”‚
â”‚  â”‚                                                      â”‚
â”‚  â””â”€ uv.lock              # Independent lock file       â”‚
â”‚                                                         â”‚
â”‚  API:                                                   â”‚
â”‚  â”œâ”€ POST /predict        # Run inference               â”‚
â”‚  â”œâ”€ GET /health          # Health check                â”‚
â”‚  â””â”€ GET /info            # Model info                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service Communication

```
Backend (config/models.yaml):
â”œâ”€â”€ mock       â†’ http://localhost:8001  # Mock service (testing)
â”œâ”€â”€ octo-small â†’ http://localhost:8002  # Python 3.11
â””â”€â”€ smolvla    â†’ http://localhost:8003  # Python 3.12

Each service:
- Imports vla-server-base via path dependency
- Has independent Python version & ML dependencies
- Runs as separate process with own uv.lock
```

---

## ðŸ“¦ Project Structure

### New Structure (Microservice Architecture)

```
mujoco-web/
â”œâ”€â”€ backend/                   # FastAPI backend (workspace member)
â”œâ”€â”€ worker/                    # ELO worker (workspace member)
â”œâ”€â”€ shared/                    # Common schemas (workspace member)
â”‚
â”œâ”€â”€ vla-server-base/          # Common library (workspace member) â­
â”‚   â”œâ”€â”€ pyproject.toml        # Python 3.9+, NO ML dependencies
â”‚   â”‚   # dependencies: fastapi, pydantic, mujoco, numpy, pillow
â”‚   â”œâ”€â”€ src/vla_server_base/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_adapter.py   # VLAModelAdapter ABC
â”‚   â”‚   â”œâ”€â”€ mujoco_env.py     # MuJoCo wrapper (stateless)
â”‚   â”‚   â”œâ”€â”€ schemas.py        # ObservationDict, ActionList, etc.
â”‚   â”‚   â””â”€â”€ server_utils.py   # FastAPI helpers
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_base_adapter.py
â”‚       â””â”€â”€ test_mujoco_env.py
â”‚
â”œâ”€â”€ vla-servers/              # Independent services (NOT workspace) â­
â”‚   â”œâ”€â”€ mock/                 # Mock service (testing)
â”‚   â”‚   â”œâ”€â”€ pyproject.toml    # Python 3.9+
â”‚   â”‚   â”‚   # vla-server-base = { path = "../../vla-server-base" }
â”‚   â”‚   â”œâ”€â”€ src/mock_service/
â”‚   â”‚   â”‚   â”œâ”€â”€ adapter.py    # MockVLAAdapter
â”‚   â”‚   â”‚   â””â”€â”€ server.py     # FastAPI app
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ uv.lock           # Independent lock
â”‚   â”‚
â”‚   â”œâ”€â”€ octo-small/           # Octo-Small service
â”‚   â”‚   â”œâ”€â”€ pyproject.toml    # Python 3.11
â”‚   â”‚   â”‚   # vla-server-base = { path = "../../vla-server-base" }
â”‚   â”‚   â”‚   # tensorflow==2.15.0, jax, flax, octo, dlimp
â”‚   â”‚   â”œâ”€â”€ src/octo_service/
â”‚   â”‚   â”‚   â”œâ”€â”€ adapter.py    # OctoSmallAdapter
â”‚   â”‚   â”‚   â””â”€â”€ server.py     # FastAPI app
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”‚   â””â”€â”€ test_adapter.py
â”‚   â”‚   â””â”€â”€ uv.lock           # Independent lock
â”‚   â”‚
â”‚   â””â”€â”€ smolvla/              # SmolVLA service (Phase 3)
â”‚       â”œâ”€â”€ pyproject.toml    # Python 3.12
â”‚       â”‚   # vla-server-base = { path = "../../vla-server-base" }
â”‚       â”‚   # torch>=2.9.0, transformers
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ models.yaml           # VLA service endpoints
â”‚   â””â”€â”€ mujoco/
â”‚       â”œâ”€â”€ template.xml
â”‚       â”œâ”€â”€ robots/
â”‚       â”‚   â””â”€â”€ franka.xml
â”‚       â””â”€â”€ scenes/
â”‚           â””â”€â”€ table.xml
â”‚
â””â”€â”€ pyproject.toml            # Root workspace
    # [tool.uv.workspace]
    # members = ["backend", "worker", "shared", "vla-server-base"]
    # exclude = ["vla-servers/*"]
```

### Python Version Policy

| Package | Python Version | Reason |
|---------|---------------|--------|
| vla-server-base | `>=3.9` | Maximum compatibility |
| mock service | `>=3.9` | Maximum compatibility |
| octo-small service | `>=3.11,<3.12` | TensorFlow 2.15.0 constraint |
| smolvla service | `>=3.12` | Latest features, PyTorch 2.9+ |

---

## ðŸ”§ Implementation Guide

### Overview of New Implementation

**Phase 1: vla-server-base (Common Library)**
1. Create vla-server-base as workspace member
2. Implement BaseAdapter, MuJoCo wrapper, schemas
3. NO ML dependencies (lightweight!)

**Phase 2: Independent Model Services**
1. Create vla-servers/mock (testing)
2. Create vla-servers/octo-small (Python 3.11)
3. Create vla-servers/smolvla (Python 3.12, Phase 3)

**Each service:**
- path dependency to vla-server-base
- Own pyproject.toml with specific Python version
- Own uv.lock (independent dependencies)
- FastAPI app with /predict, /health, /info endpoints

---

### Step 1: Root Config Setup

**Create config/mujoco/ structure:**

```bash
mkdir -p config/mujoco/{robots,scenes}
```

**config/mujoco/template.xml:**

```xml
<mujoco model="{model_name}">
  <compiler angle="radian"/>
  <option timestep="0.002"/>

  <asset>
    <texture name="grid" type="2d" builtin="checker" width="512" height="512"/>
    <material name="grid" texture="grid" texrepeat="1 1" texuniform="true"/>
  </asset>

  <worldbody>
    <light pos="0 0 3" dir="0 0 -1"/>
    <geom name="floor" pos="0 0 0" size="0 0 .05" type="plane" material="grid"/>

    {scene_body}
    {robot_body}
  </worldbody>
</mujoco>
```

**config/mujoco/robots/franka.xml:**

```xml
<body name="franka_base" pos="0 0 0">
  <inertial pos="0 0 0" mass="4" diaginertia="0.4 0.4 0.4"/>
  <geom type="cylinder" size="0.06 0.05" rgba="0.7 0.7 0.7 1"/>

  <!-- Simplified Franka arm for MVP -->
  <body name="link1" pos="0 0 0.1">
    <joint name="joint1" type="hinge" axis="0 0 1"/>
    <geom type="cylinder" size="0.05 0.1" rgba="0.9 0.9 0.9 1"/>

    <body name="link2" pos="0 0 0.2">
      <joint name="joint2" type="hinge" axis="0 1 0"/>
      <geom type="cylinder" size="0.045 0.1" rgba="0.9 0.9 0.9 1"/>

      <!-- Add remaining joints... -->
      <!-- Total: 7 joints + gripper (8 actuators) -->
    </body>
  </body>
</body>
```

**config/mujoco/scenes/table.xml:**

```xml
<body name="table" pos="0.5 0 0">
  <geom name="table_top" type="box" size="0.4 0.4 0.02" pos="0 0 0.4" rgba="0.8 0.6 0.4 1"/>
  <geom name="table_leg1" type="cylinder" size="0.03 0.2" pos="-0.35 -0.35 0.2"/>
  <geom name="table_leg2" type="cylinder" size="0.03 0.2" pos="-0.35 0.35 0.2"/>
  <geom name="table_leg3" type="cylinder" size="0.03 0.2" pos="0.35 -0.35 0.2"/>
  <geom name="table_leg4" type="cylinder" size="0.03 0.2" pos="0.35 0.35 0.2"/>

  <!-- Add objects for manipulation -->
  <body name="red_cube" pos="0 0 0.45">
    <joint type="free"/>
    <geom type="box" size="0.03 0.03 0.03" rgba="1 0 0 1" mass="0.1"/>
  </body>
</body>
```

---

### Step 2: VLA Server Configuration

**vla-server/src/vla_server/config/settings.py:**

```python
"""
Configuration for VLA Server
Uses Pydantic Settings for environment variable management
"""

from pathlib import Path
from pydantic_settings import BaseSettings, SettingsConfigDict

# Root .env file location (mujoco-web-vla/.env)
ROOT_ENV_FILE = Path(__file__).parent.parent.parent.parent.parent / ".env"


class Settings(BaseSettings):
    """VLA Server settings"""

    model_config = SettingsConfigDict(env_prefix="VLA_", env_file=str(ROOT_ENV_FILE))

    # Server
    host: str = "0.0.0.0"
    port: int = 8001
    reload: bool = True

    # Model (REQUIRED - determines which adapter to use)
    model_id: str  # "mock", "octo-small", "smolvla"

    # Models & Paths
    vla_model_cache: str = "./model_cache"
    device: str = "auto"  # auto (cuda â†’ mps â†’ cpu), cuda, cpu, mps

    # Execution - based on RT-1/Octo standards
    control_frequency: float = 5.0  # Hz (RT-1/Octo standard: 3-5 Hz)
    max_episode_seconds: float = 15.0  # seconds (typical task duration)

    # Logging
    log_level: str = "INFO"


settings = Settings()
```

**vla-server/src/vla_server/config/model_loader.py:**

```python
"""
MuJoCo model XML composition
Dynamically combines robot and scene XMLs
"""

from pathlib import Path


# Root config directory
ROOT_CONFIG = Path(__file__).parent.parent.parent.parent.parent / "config" / "mujoco"


def get_model_xml(robot_id: str, scene_id: str) -> str:
    """
    Dynamically compose MuJoCo XML from robot and scene

    Args:
        robot_id: Robot identifier (e.g., "franka")
        scene_id: Scene identifier (e.g., "table")

    Returns:
        Complete MuJoCo XML string

    Raises:
        FileNotFoundError: If robot or scene XML not found
    """
    # Load template
    template_path = ROOT_CONFIG / "template.xml"
    if not template_path.exists():
        raise FileNotFoundError(f"Template not found: {template_path}")
    template = template_path.read_text()

    # Load robot body
    robot_path = ROOT_CONFIG / "robots" / f"{robot_id}.xml"
    if not robot_path.exists():
        raise FileNotFoundError(f"Robot not found: {robot_path}")
    robot_xml = robot_path.read_text()

    # Load scene body
    scene_path = ROOT_CONFIG / "scenes" / f"{scene_id}.xml"
    if not scene_path.exists():
        raise FileNotFoundError(f"Scene not found: {scene_path}")
    scene_xml = scene_path.read_text()

    # Compose final XML
    final_xml = template.format(
        model_name=f"{robot_id}_{scene_id}",
        robot_body=robot_xml,
        scene_body=scene_xml
    )

    return final_xml
```

---

### Step 3: Stateless MuJoCo Environment

**vla-server/src/vla_server/services/mujoco_env.py:**

```python
"""
MuJoCo environment management for VLA execution
Stateless design - accepts XML string directly
"""

import mujoco
import numpy as np


class MuJoCoEnvironment:
    """Stateless MuJoCo simulation environment"""

    def __init__(self, xml_string: str):
        """
        Initialize MuJoCo environment from XML string

        Args:
            xml_string: Complete MuJoCo XML model
        """
        # Load model from XML string (stateless!)
        self.model = mujoco.MjModel.from_xml_string(xml_string)
        self.data = mujoco.MjData(self.model)

        # Renderer for observations (224x224 for VLA models)
        self.renderer = mujoco.Renderer(self.model, height=224, width=224)

        # Store initial state
        self.initial_qpos = self.data.qpos.copy()
        self.initial_qvel = self.data.qvel.copy()

    def reset(self) -> dict:
        """
        Reset environment to initial state

        Returns:
            Observation after reset
        """
        self.data.qpos[:] = self.initial_qpos
        self.data.qvel[:] = self.initial_qvel
        self.data.time = 0.0
        mujoco.mj_forward(self.model, self.data)

        return self.get_observation()

    def step(self, action: list[float]) -> dict:
        """
        Step simulation with action

        Args:
            action: 8-dim action vector (7 joints + gripper)

        Returns:
            Observation after step
        """
        # Convert to numpy array
        action_array = np.array(action, dtype=np.float32)

        # Apply action to actuators (truncate or pad as needed)
        num_actuators = self.model.nu
        if len(action_array) >= num_actuators:
            self.data.ctrl[:] = action_array[:num_actuators]
        else:
            self.data.ctrl[:len(action_array)] = action_array
            self.data.ctrl[len(action_array):] = 0.0

        # Step simulation
        mujoco.mj_step(self.model, self.data)

        return self.get_observation()

    def get_observation(self) -> dict:
        """
        Get current observation

        Returns:
            Dictionary with image, qpos, qvel
        """
        # Render image
        self.renderer.update_scene(self.data)
        image = self.renderer.render()

        return {
            "image": image,
            "qpos": self.data.qpos.copy(),
            "qvel": self.data.qvel.copy(),
        }

    def get_state(self) -> dict:
        """
        Get current state for episode recording

        Returns:
            Dictionary with qpos, qvel, time (as lists for JSON serialization)
        """
        return {
            "qpos": self.data.qpos.tolist(),
            "qvel": self.data.qvel.tolist(),
            "time": float(self.data.time),
        }
```

---

### Step 4: VLA Adapter Pattern

**vla-server/src/vla_server/adapters/base.py:**

```python
"""
Abstract base class for VLA model adapters
Defines interface for model-specific preprocessing/postprocessing
"""

from abc import ABC, abstractmethod
from typing import Any
import numpy as np


class VLAModelAdapter(ABC):
    """Abstract VLA model adapter"""

    @abstractmethod
    def load_model(self, model_id: str, device: str, cache_dir: str):
        """
        Load VLA model

        Args:
            model_id: Model identifier
            device: torch device (cuda, mps, cpu)
            cache_dir: HuggingFace cache directory
        """
        pass

    @abstractmethod
    def preprocess_observation(self, obs: dict) -> Any:
        """
        Preprocess observation to model-specific format

        Args:
            obs: Standard observation dict
                - image: (H, W, 3) RGB uint8
                - qpos: (n,) joint positions
                - qvel: (n,) joint velocities

        Returns:
            Model-specific observation format
        """
        pass

    @abstractmethod
    def preprocess_instruction(self, instruction: str) -> Any:
        """
        Preprocess text instruction to model-specific format

        Args:
            instruction: Natural language instruction

        Returns:
            Model-specific instruction format
        """
        pass

    @abstractmethod
    def predict(self, obs: Any, instruction: Any) -> Any:
        """
        Run model inference

        Args:
            obs: Preprocessed observation
            instruction: Preprocessed instruction

        Returns:
            Raw model output
        """
        pass

    @abstractmethod
    def postprocess_action(self, raw_action: Any) -> list[float]:
        """
        Postprocess model output to standard 8-dim action

        Args:
            raw_action: Raw model output

        Returns:
            8-dim action list [j1, j2, ..., j7, gripper]
        """
        pass
```

**vla-server/src/vla_server/adapters/openvla_adapter.py:**

```python
"""
OpenVLA adapter
Model-specific preprocessing/postprocessing for OpenVLA 7B
"""

import torch
from transformers import AutoModel, AutoProcessor
from .base import VLAModelAdapter


class OpenVLAAdapter(VLAModelAdapter):
    """Adapter for OpenVLA 7B model"""

    def load_model(self, model_id: str, device: str, cache_dir: str):
        """Load OpenVLA model from HuggingFace"""
        hub_id = "openvla/openvla-7b"

        self.device = device
        self.processor = AutoProcessor.from_pretrained(hub_id, cache_dir=cache_dir)
        self.model = AutoModel.from_pretrained(
            hub_id,
            cache_dir=cache_dir,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32
        )
        self.model = self.model.to(device)
        self.model.eval()

    def preprocess_observation(self, obs: dict):
        """OpenVLA expects 256x256 images"""
        from PIL import Image

        # Convert to PIL Image and resize
        image = Image.fromarray(obs["image"])
        image_resized = image.resize((256, 256))

        return {
            "image": image_resized,
            "qpos": obs["qpos"],
            "qvel": obs["qvel"],
        }

    def preprocess_instruction(self, instruction: str):
        """OpenVLA uses standard text encoding"""
        return instruction

    def predict(self, obs, instruction):
        """Run OpenVLA inference"""
        # Process inputs
        inputs = self.processor(
            images=obs["image"],
            text=instruction,
            return_tensors="pt"
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        # Inference
        with torch.no_grad():
            outputs = self.model(**inputs)
            action = outputs.action  # Model-specific output format

        return action

    def postprocess_action(self, raw_action):
        """Convert OpenVLA output to 8-dim action"""
        # OpenVLA outputs 8-dim action directly
        action_np = raw_action.cpu().numpy()
        if action_np.ndim > 1:
            action_np = action_np[0]  # Remove batch dimension

        return action_np.tolist()
```

**vla-server/src/vla_server/adapters/octo_adapter.py:**

```python
"""
Octo adapter
Model-specific preprocessing/postprocessing for Octo-Base
"""

import torch
from transformers import AutoModel, AutoProcessor
from .base import VLAModelAdapter


class OctoAdapter(VLAModelAdapter):
    """Adapter for Octo-Base model"""

    def load_model(self, model_id: str, device: str, cache_dir: str):
        """Load Octo model from HuggingFace"""
        hub_id = "octo-models/octo-base"

        self.device = device
        self.processor = AutoProcessor.from_pretrained(hub_id, cache_dir=cache_dir)
        self.model = AutoModel.from_pretrained(hub_id, cache_dir=cache_dir)
        self.model = self.model.to(device)
        self.model.eval()

    def preprocess_observation(self, obs: dict):
        """Octo expects 224x224 images (already correct size)"""
        return {
            "image": obs["image"],
            "qpos": obs["qpos"],
        }

    def preprocess_instruction(self, instruction: str):
        """Octo uses standard text encoding"""
        return instruction

    def predict(self, obs, instruction):
        """Run Octo inference"""
        # Process inputs
        inputs = self.processor(
            images=obs["image"],
            text=instruction,
            return_tensors="pt"
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        # Inference
        with torch.no_grad():
            outputs = self.model(**inputs)
            action = outputs.action

        return action

    def postprocess_action(self, raw_action):
        """Convert Octo output to 8-dim action"""
        action_np = raw_action.cpu().numpy()
        if action_np.ndim > 1:
            action_np = action_np[0]

        # Octo outputs 7-dim (no gripper), pad with 0
        if len(action_np) == 7:
            action_np = np.append(action_np, 0.0)

        return action_np.tolist()
```

**vla-server/src/vla_server/adapters/__init__.py:**

```python
"""
VLA adapter factory
Returns appropriate adapter based on model_id
"""

from .base import VLAModelAdapter
from .openvla_adapter import OpenVLAAdapter
from .octo_adapter import OctoAdapter


def get_adapter(model_id: str) -> VLAModelAdapter:
    """
    Get VLA adapter for given model

    Args:
        model_id: Model identifier

    Returns:
        Appropriate VLAModelAdapter instance

    Raises:
        ValueError: If model_id not recognized
    """
    adapters = {
        "openvla-7b": OpenVLAAdapter,
        "octo-base": OctoAdapter,
    }

    adapter_class = adapters.get(model_id)
    if not adapter_class:
        raise ValueError(f"Unknown model_id: {model_id}. Available: {list(adapters.keys())}")

    return adapter_class()


__all__ = ["VLAModelAdapter", "get_adapter", "OpenVLAAdapter", "OctoAdapter"]
```

---

### Step 5: Execution Service

**vla-server/src/vla_server/services/execution_service.py:**

```python
"""
Execution service - orchestrates MuJoCo + VLA Adapter
"""

import time
from ..config import settings
from ..config.model_loader import get_model_xml
from ..adapters import get_adapter
from .mujoco_env import MuJoCoEnvironment
from ..schemas.execute import ExecuteRequest, ExecuteResponse, State


class ExecutionService:
    """Service for executing VLA episodes"""

    def __init__(self):
        # Load adapter for this server's model
        self.adapter = get_adapter(settings.model_id)
        self.adapter.load_model(
            model_id=settings.model_id,
            device=settings.device,
            cache_dir=settings.vla_model_cache
        )

        # Detect actual device
        if settings.device == "auto":
            import torch
            if torch.cuda.is_available():
                self.device = "cuda"
            elif torch.backends.mps.is_available():
                self.device = "mps"
            else:
                self.device = "cpu"
        else:
            self.device = settings.device

    async def execute(self, request: ExecuteRequest) -> ExecuteResponse:
        """
        Execute VLA episode

        Args:
            request: Execution request (robot_id, scene_id, instruction)

        Returns:
            Episode data with actions and states
        """
        start_time = time.time()

        # 1. Compose MuJoCo XML (stateless)
        xml_string = get_model_xml(request.robot_id, request.scene_id)

        # 2. Create MuJoCo environment (from XML string)
        env = MuJoCoEnvironment(xml_string)

        # 3. Reset environment
        env.reset()

        # 4. Calculate max steps
        max_steps = int(settings.max_episode_seconds * settings.control_frequency)

        # 5. Run episode loop
        actions = []
        states = []

        for step in range(max_steps):
            # Get observation
            obs = env.get_observation()

            # Adapter preprocessing
            obs_processed = self.adapter.preprocess_observation(obs)
            instruction_processed = self.adapter.preprocess_instruction(request.instruction)

            # VLA inference
            raw_action = self.adapter.predict(obs_processed, instruction_processed)

            # Adapter postprocessing
            action = self.adapter.postprocess_action(raw_action)

            # Step simulation
            env.step(action)

            # Record
            actions.append(action)
            states.append(State(**env.get_state()))

        # 6. Calculate duration
        duration_ms = int((time.time() - start_time) * 1000)

        # 7. Return response
        return ExecuteResponse(
            actions=actions,
            states=states,
            duration_ms=duration_ms,
            metadata={
                "model_id": settings.model_id,
                "num_steps": len(actions),
                "max_steps": max_steps,
                "control_frequency": settings.control_frequency,
                "device": self.device,
            },
        )
```

---

### Step 6: Schemas

**vla-server/src/vla_server/schemas/execute.py:**

```python
"""
Request/Response schemas for /execute endpoint
"""

from pydantic import BaseModel, Field


class ExecuteRequest(BaseModel):
    """Request to execute VLA model in MuJoCo environment"""

    # Note: model_id is NOT in request - server already knows its model
    robot_id: str = Field(..., description="Robot type (e.g., 'franka')")
    scene_id: str = Field(..., description="Scene type (e.g., 'table')")
    instruction: str = Field(..., min_length=1, description="Natural language instruction")

    class Config:
        json_schema_extra = {
            "example": {
                "robot_id": "franka",
                "scene_id": "table",
                "instruction": "Pick up the red cube",
            }
        }


class State(BaseModel):
    """MuJoCo state at a single timestep"""

    qpos: list[float] = Field(..., description="Joint positions")
    qvel: list[float] = Field(..., description="Joint velocities")
    time: float = Field(..., description="Simulation time")


class ExecuteResponse(BaseModel):
    """Response containing episode data"""

    actions: list[list[float]] = Field(..., description="Action sequence")
    states: list[State] = Field(..., description="State sequence (same length as actions)")
    duration_ms: int = Field(..., description="Execution duration in milliseconds")
    metadata: dict = Field(
        default_factory=dict,
        description="Additional metadata (model_id, num_steps, device, etc.)",
    )

    class Config:
        json_schema_extra = {
            "example": {
                "actions": [[0.1, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]],
                "states": [{"qpos": [0.0] * 7, "qvel": [0.0] * 7, "time": 0.0}],
                "duration_ms": 5120,
                "metadata": {
                    "model_id": "openvla-7b",
                    "num_steps": 75,
                    "max_steps": 75,
                    "control_frequency": 5.0,
                    "device": "cuda"
                },
            }
        }
```

---

### Step 7: API Endpoint

**vla-server/src/vla_server/api/execute.py:**

```python
"""
Execute endpoint - POST /execute
"""

from fastapi import APIRouter, HTTPException, status
from ..schemas.execute import ExecuteRequest, ExecuteResponse
from ..services.execution_service import ExecutionService


router = APIRouter(prefix="", tags=["execution"])

# Global service instance (model loaded once at startup)
execution_service = ExecutionService()


@router.post("/execute", response_model=ExecuteResponse)
async def execute_vla(request: ExecuteRequest):
    """
    Execute VLA model in MuJoCo environment

    Args:
        request: Execution request (robot, scene, instruction)

    Returns:
        Episode data with actions and states
    """
    try:
        response = await execution_service.execute(request)
        return response

    except FileNotFoundError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Robot or scene not found: {str(e)}",
        )

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Invalid request: {str(e)}",
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Execution failed: {str(e)}",
        )


@router.get("/info")
async def get_server_info():
    """Get information about this VLA server instance"""
    from ..config import settings

    return {
        "model_id": settings.model_id,
        "device": execution_service.device,
        "max_episode_seconds": settings.max_episode_seconds,
        "control_frequency": settings.control_frequency,
    }
```

---

## ðŸ“… Implementation Timeline

### Week 3: Infrastructure + Restructuring
- [x] Root config setup (config/mujoco/) âœ… Phase 1
- [x] XML composition logic (10 tests) âœ… Phase 1
- [x] Stateless MuJoCo environment (16 tests) âœ… Phase 1
- [x] VLA adapter base class âœ… Phase 2 PR 1
- [x] Mock adapter (20 tests) âœ… Phase 2 PR 1
- [x] **Architecture Restructuring** (Phase 2 Reboot) âœ…
  - [x] vla-server â†’ vla-server-base (remove ML deps) âœ… PR #32
  - [x] Create vla-servers/ folder âœ… PR #35
  - [x] vla-servers/mock service âœ… PR #35
  - [x] vla-servers/octo-small service (Python 3.10, TensorFlow 2.15.0) âœ… PR #36
  - [x] Update root workspace config âœ… PR #32

### Week 4: Model Integration & Testing âœ…
- [x] Each service with FastAPI app âœ… PR #36 (octo-small complete)
- [x] Complete OctoSmallAdapter implementation âœ… PR #36
- [x] Service-specific tests (per service) âœ… PR #36 (12 unit tests)
- [x] Multi-service testing (mock + octo-small) âœ… PR #43
  - [x] Multi-service integration tests (18 tests)
  - [x] Backend â†’ VLA â†’ MongoDB full flow tests (6 tests)
  - [x] Performance testing (< 60s)
  - [x] Error scenarios (service down, timeout)
- [x] Error handling & validation âœ… PR #36

### Week 5: SmolVLA & Optimization (Deferred)
- [ ] vla-servers/smolvla service (Python 3.12) - Deferred to post-MVP
- [x] Integration test documentation âœ… (tests/integration/README.md)
- [x] Multi-service testing guide âœ…
- [x] Performance benchmarks âœ…

---

## ðŸ§ª Testing Strategy

### Unit Tests (70 passing)

**vla-server-base (45 tests):**
- XML Composition (10 tests) - Model loader
- MuJoCo Environment (16 tests) - Stateless simulation
- Episode Executor (9 tests) - Episode generation
- App Factory (10 tests) - FastAPI app creation

**vla-servers/mock (13 tests):**
- Mock adapter implementation
- Deterministic action generation
- Error handling

**vla-servers/octo-small (12 tests):**
- Octo-Small adapter implementation
- JAX/Flax integration
- TensorFlow compatibility

### Integration Tests (24 ready)

**Multi-Service Tests (18 tests) - `test_multi_service.py`:**
- Health Checks (3 tests)
- Service Info (3 tests)
- Predictions (4 tests)
- Error Scenarios (3 tests)
- Performance (3 tests)
- Communication Patterns (2 tests)

**Backend Integration Tests (6 tests) - `test_backend_vla_integration.py`:**
- Session creation via Backend API
- Turn creation with Mock VLA
- Backend â†’ VLA â†’ MongoDB full flow
- Episode data storage verification
- Multi-turn battle flow
- Performance testing (< 60s)
- Error handling (VLA server down)

**How to Run:**
```bash
# Unit tests only
uv run pytest

# Integration tests (requires services running)
uv run pytest tests/integration/ --run-integration -v
```

See `tests/integration/README.md` for detailed integration test guide.

---

## ðŸš€ Deployment

### Starting VLA Services (New Architecture)

```bash
# Start Mock service (port 8001)
cd vla-servers/mock
uv sync
uv run uvicorn mock_service.server:app --port 8001 --reload

# Start Octo-Small service (port 8002, Python 3.11 required)
cd vla-servers/octo-small
uv sync  # Installs tensorflow 2.15.0, jax, octo in Python 3.11
uv run uvicorn octo_service.server:app --port 8002 --reload

# Start SmolVLA service (port 8003, Python 3.12)
cd vla-servers/smolvla
uv sync  # Installs torch 2.9+, transformers
uv run uvicorn smolvla_service.server:app --port 8003 --reload
```

### Testing Endpoints

```bash
# Test Mock service
curl -X POST http://localhost:8001/predict \
  -H "Content-Type: application/json" \
  -d '{
    "obs": {"image": [...], "qpos": [...], "qvel": [...]},
    "instruction": "Pick up the red cube"
  }'

# Test Octo-Small service
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{
    "obs": {"image": [...], "qpos": [...], "qvel": [...]},
    "instruction": "Pick up the red cube"
  }'

# Get service info
curl http://localhost:8001/info
curl http://localhost:8002/info
```

### Backend Integration

Backend uses `config/models.yaml` to route requests to appropriate VLA server:

```yaml
models:
  - id: mock
    base_url: http://localhost:8001  # Mock server (testing)

  - id: octo-small
    base_url: http://localhost:8002  # Octo-Small server

  - id: smolvla
    base_url: http://localhost:8003  # SmolVLA server
```

---

## ðŸ“Š Success Criteria

**Phase 1 Complete (Infrastructure):** âœ…
1. âœ… Root config/mujoco/ structure created
2. âœ… XML composition works (dynamic robot+scene) - 10 tests passing
3. âœ… Stateless MuJoCo environment (XML string input) - 16 tests passing

**Phase 2 Complete (VLA Integration):** âœ…
4. âœ… Adapter pattern base implemented (VLAModelAdapter ABC)
5. âœ… Mock adapter implemented (13 tests passing)
6. âœ… Octo-Small adapter (12 tests passing) - PR #36
7. â¸ï¸ SmolVLA adapter - Deferred to post-MVP
8. âœ… Multi-server deployment works
9. âœ… Episodes generated (variable steps @ 5 Hz)
10. âœ… Backend integration successful - PR #40, #41
11. âœ… All tests pass (260 tests: 236 unit + 24 integration) âœ…
12. âœ… MacBook compatible (CPU/MPS)

**Phase 3 Complete (Multi-Service Integration):** âœ…
13. âœ… Multi-service integration tests (18 tests)
14. âœ… Backend â†’ VLA â†’ MongoDB full flow tests (6 tests)
15. âœ… Performance testing (< 60s)
16. âœ… Error scenarios (service down, timeout)
17. âœ… Integration test documentation

---

## ðŸ”„ Migration from Previous Architecture

**Changes from v1:**
1. âŒ Removed: `vla_model.py` (monolithic model manager)
2. âœ… Added: `adapters/` (model-specific preprocessing)
3. âœ… Added: `config/model_loader.py` (XML composition)
4. âœ… Changed: `MuJoCoEnvironment.__init__(xml_string)` (was file path)
5. âœ… Changed: API request - no `model_id` field (server knows its model)
6. âœ… Added: `VLA_MODEL_ID` environment variable (server startup)

**Why?**
- **Extensibility**: Easy to add new models (just add adapter)
- **Stateless**: No file system dependency for MuJoCo
- **Scalability**: Each model runs as separate server instance
- **Testability**: Mock XML strings for tests

---

## ðŸ“š References

### Models
- **OpenVLA:** https://openvla.github.io/
- **Octo:** https://octo-models.github.io/

### Documentation
- **ADR-003:** VLA Server Separation
- **config/models.yaml:** VLA model endpoints
- **ROADMAP.md:** Development timeline
- **001_MVP.md:** Overall MVP scope

---

**Created:** 2025-01-06
**Last Updated:** 2025-11-10 (Multi-Service Integration Complete)
**Status:** âœ… Complete - Multi-Service Integration Testing Done
**Architecture:** Microservice pattern (vla-server-base + vla-servers/)
**Test Coverage:** 260 tests (236 unit + 24 integration)
**Services Ready:**
- âœ… vla-server-base (common library, 45 tests)
- âœ… vla-servers/mock (13 tests)
- âœ… vla-servers/octo-small (12 tests, Python 3.10)
- â¸ï¸ vla-servers/smolvla (deferred to post-MVP)

**Next Steps:**
- SmolVLA service implementation (optional)
- MVP finalization and deployment
